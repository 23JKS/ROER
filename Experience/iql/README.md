# IQL + ROER å®ç°

å°†**ROER (Regularized Optimal Experience Replay)** é›†æˆåˆ° **IQL (Implicit Q-Learning)** ç®—æ³•ä¸­ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

```
iql/
â”œâ”€â”€ iql_roer_learner.py      # IQL+ROERæ ¸å¿ƒç®—æ³•
â”œâ”€â”€ train_iql_roer.py         # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ replay_buffer_roer.py     # å¸¦ROERä¼˜å…ˆçº§çš„replay buffer
â”œâ”€â”€ common.py                 # åŸºç¡€ç±»å’Œç±»å‹
â”œâ”€â”€ policies.py               # ç­–ç•¥ç½‘ç»œ
â”œâ”€â”€ temperature.py            # æ¸©åº¦å‚æ•°
â”œâ”€â”€ env_utils.py              # ç¯å¢ƒå·¥å…·
â”œâ”€â”€ evaluation_utils.py       # è¯„ä¼°å‡½æ•°
â”œâ”€â”€ run_iql_comparison.sh     # IQL vs IQL+ROERå¯¹æ¯”å®éªŒ
â”œâ”€â”€ quick_test.sh             # å¿«é€Ÿæµ‹è¯•
â”œâ”€â”€ run_ant_experiment.sh     # Ant-v2ä¸“ç”¨å®éªŒ
â””â”€â”€ README.md                 # æœ¬æ–‡ä»¶
```

## ğŸ¯ æ ¸å¿ƒåˆ›æ–°ç‚¹

### 1. IQLç®—æ³•ç‰¹ç‚¹ï¼ˆ2022ï¼‰

- **Expectile Regression** - æ›´ç¨³å®šçš„Qå€¼ä¼°è®¡
- **Advantage-Weighted BC** - éšå¼ç­–ç•¥å­¦ä¹ ï¼Œæ— éœ€explicit actor
- **ç®€å•é«˜æ•ˆ** - æ¯”EDACæ›´ç®€å•ï¼Œæ€§èƒ½æ›´å¥½
- **SOTAæ€§èƒ½** - åœ¨D4RLä¸Šè¶…è¶ŠEDAC

### 2. ROERä¼˜å…ˆçº§æœºåˆ¶

- **ç†è®ºåŸºç¡€**: åŸºäºå ç”¨ä¼˜åŒ–æ¨å¯¼
- **å…¬å¼**: `w âˆ exp(TD_error / Î²)`
- **æ›´æ–°**: EMAå¹³æ»‘

### 3. IQL+ROERé›†æˆæ–¹æ¡ˆ

**ä¼˜åŠ¿**ï¼š
- IQLçš„expectile regressionæ›´ç¨³å®šï¼Œä¸ROERé…åˆæ›´å¥½
- ä½¿ç”¨Vç½‘ç»œè®¡ç®—TDè¯¯å·®ï¼Œç¬¦åˆActor-Criticç†è®º
- æ— éœ€ensembleï¼Œè®­ç»ƒæ›´å¿«

**å®ç°ç»†èŠ‚**ï¼š
1. **Qç½‘ç»œæ›´æ–°**: ä½¿ç”¨ROERæƒé‡åŠ æƒTD loss
2. **Vç½‘ç»œæ›´æ–°**: åœ¨expectile lossä¸­åŠ å…¥ROERæƒé‡
3. **Actoræ›´æ–°**: ä¿æŒIQLçš„advantage-weighted BC
4. **ä¼˜å…ˆçº§è®¡ç®—**: ä½¿ç”¨Vç½‘ç»œçš„TDè¯¯å·®

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨åŸROERç¯å¢ƒ
conda activate roer

# ç¡®ä¿ç¯å¢ƒæ­£ç¡®
cd ~/Regularized-Optimal-Experience-Replay
```

### å¿«é€Ÿæµ‹è¯•

```bash
cd Experience/iql

# æ·»åŠ æ‰§è¡Œæƒé™
chmod +x *.sh

# è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆ10kæ­¥ï¼Œçº¦5-10åˆ†é’Ÿï¼‰
./quick_test.sh
```

### å•æ¬¡è®­ç»ƒ

```bash
# IQL+ROER
python train_iql_roer.py \
    --env_name=HalfCheetah-v2 \
    --seed=42 \
    --use_roer=True \
    --roer_temp=4.0 \
    --roer_max_clip=50 \
    --roer_min_clip=10 \
    --expectile=0.7 \
    --iql_beta=3.0

# IQL baseline
python train_iql_roer.py \
    --env_name=HalfCheetah-v2 \
    --seed=42 \
    --use_roer=False \
    --expectile=0.7 \
    --iql_beta=3.0
```

## ğŸ“Š å®éªŒè„šæœ¬

### 1. å¯¹æ¯”å®éªŒ

æ¯”è¾ƒIQLå’ŒIQL+ROERçš„æ€§èƒ½ï¼š

```bash
# è¿è¡Œ5ä¸ªç§å­çš„å¯¹æ¯”å®éªŒ
./run_iql_comparison.sh HalfCheetah-v2 5

# Ant-v2å®éªŒ
./run_ant_experiment.sh 5
```

### 2. æŸ¥çœ‹ç»“æœ

```bash
# TensorBoard
tensorboard --logdir ~/roer_output/results/

# æŸ¥çœ‹è¯„ä¼°å†å²
cat ~/roer_output/results/iql_roer/*/eval_returns.txt
```

## ğŸ”§ å…³é”®å‚æ•°è¯´æ˜

### IQLå‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | æ¨èèŒƒå›´ |
|------|------|--------|----------|
| `expectile` | Expectileå‚æ•° | 0.7 | 0.7-0.9 |
| `iql_beta` | Advantage weightingæ¸©åº¦ | 3.0 | 1.0-10.0 |

### ROERå‚æ•°

| å‚æ•° | è¯´æ˜ | MuJoCoé»˜è®¤ | DM Controlé»˜è®¤ |
|------|------|-----------|---------------|
| `roer_temp` (Î²) | æ¸©åº¦å‚æ•° | 4.0 | 1.0 |
| `roer_max_clip` | æœ€å¤§ä¼˜å…ˆçº§è£å‰ª | 50 | 100 |
| `roer_min_clip` | æœ€å°ä¼˜å…ˆçº§è£å‰ª | 10 | 10 |
| `roer_per_beta` (Î») | EMAç³»æ•° | 0.01 | 0.01 |

### Ant-v2æ¨èå‚æ•°

```bash
--expectile=0.7 \
--iql_beta=3.0 \
--roer_temp=1.0 \
--roer_max_clip=100.0 \
--roer_min_clip=10.0
```

## ğŸ“ˆ é¢„æœŸç»“æœ

### æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | HalfCheetah-v2 | Ant-v2 | Hopper-v2 |
|------|---------------|--------|-----------|
| IQL Baseline | ~12500 | ~1800 | ~3200 |
| IQL+ROER | ~13000? | ~2000? | ~3400? |

**æ³¨æ„**: è¿™äº›æ˜¯é¢„æœŸå€¼ï¼Œå®é™…ç»“æœéœ€è¦å®éªŒéªŒè¯ã€‚

### IQL vs EDAC

| ç‰¹æ€§ | IQL | EDAC |
|------|-----|------|
| å¤æ‚åº¦ | ç®€å• | å¤æ‚ï¼ˆensembleï¼‰ |
| è®­ç»ƒé€Ÿåº¦ | å¿« | è¾ƒæ…¢ |
| D4RLæ€§èƒ½ | æ›´å¥½ | å¥½ |
| åœ¨çº¿RL | å¥½ | å¾ˆå¥½ |
| å®ç°éš¾åº¦ | ä½ | ä¸­ |

## ğŸ”¬ ç®—æ³•ç»†èŠ‚

### IQLçš„æ ¸å¿ƒæ€æƒ³

1. **Expectile Regression**
   ```python
   # ä¸å¯¹ç§°çš„MSE loss
   weight = where(Q - V > 0, Ï„, 1-Ï„)
   loss = weight * (Q - V)Â²
   ```
   - Ï„=0.7æ—¶ï¼Œæ›´å…³æ³¨Q > Vçš„æƒ…å†µ
   - é¿å…Qå€¼è¿‡ä¼°è®¡

2. **Advantage-Weighted BC**
   ```python
   # æ ¹æ®advantageåŠ æƒè¡Œä¸ºå…‹éš†
   weight = exp(Advantage / Î²)
   loss = -weight * log Ï€(a|s)
   ```
   - åªæ¨¡ä»¿é«˜advantageçš„åŠ¨ä½œ
   - éšå¼å­¦ä¹ ç­–ç•¥ï¼Œæ— éœ€æ˜¾å¼ä¼˜åŒ–

### ROERé›†æˆåˆ°IQL

```python
# 1. Qç½‘ç»œæ›´æ–°ï¼ˆåŠ ROERæƒé‡ï¼‰
q_loss = mean(w * (q - target_q)Â²)

# 2. Vç½‘ç»œæ›´æ–°ï¼ˆexpectile loss + ROERæƒé‡ï¼‰
v_loss = mean(w * expectile_loss(q - v, Ï„))

# 3. Actoræ›´æ–°ï¼ˆä¿æŒIQLåŸæ ·ï¼‰
actor_loss = -mean(exp(adv/Î²) * log_prob)

# 4. ä¼˜å…ˆçº§è®¡ç®—ï¼ˆVç½‘ç»œçš„TDè¯¯å·®ï¼‰
td_error = r + Î³V(s') - V(s)
priority = exp(td_error / Î²_roer)
```

## ğŸ’¡ è°ƒè¯•å»ºè®®

### å¦‚æœè®­ç»ƒä¸ç¨³å®š

1. **é™ä½expectile**: `--expectile=0.6`
2. **å¢å¤§iql_beta**: `--iql_beta=5.0`ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰
3. **é™ä½roer_temp**: `--roer_temp=2.0`
4. **ç¼©å°ä¼˜å…ˆçº§èŒƒå›´**: `--roer_max_clip=20 --roer_min_clip=5`

### å¦‚æœæ€§èƒ½æ²¡æå‡

1. **æ£€æŸ¥ä¼˜å…ˆçº§æ˜¯å¦ç”Ÿæ•ˆ**:
   - æŸ¥çœ‹TensorBoardçš„`priority/std`ï¼Œåº”è¯¥ > 0
   
2. **å°è¯•ä¸åŒexpectile**:
   ```bash
   for exp in 0.6 0.7 0.8 0.9; do
       python train_iql_roer.py --expectile=$exp
   done
   ```

3. **è°ƒæ•´ROERæ¸©åº¦**:
   ```bash
   for temp in 1.0 2.0 4.0 8.0; do
       python train_iql_roer.py --roer_temp=$temp
   done
   ```

## ğŸ“ æ¯•è®¾å»ºè®®

### ä¸ºä»€ä¹ˆIQL+ROERæ˜¯å¥½é€‰æ‹©

1. **IQLæ›´æ–°ï¼ˆ2022ï¼‰** - æ¯”EDACï¼ˆ2021ï¼‰æ›´æ–°
2. **æ€§èƒ½æ›´å¼º** - D4RLä¸Šè¶…è¶ŠEDAC
3. **å®ç°ç®€å•** - æ›´å®¹æ˜“è°ƒè¯•å’Œç†è§£
4. **åˆ›æ–°æ˜ç¡®** - ROER+IQLæ˜¯æ–°ç»„åˆ

### è®ºæ–‡å†™ä½œå»ºè®®

**IQLä»‹ç»**ï¼š
> "æˆ‘ä»¬é€‰æ‹©IQL (Implicit Q-Learning) ä½œä¸ºåŸºçº¿ç®—æ³•ã€‚IQLæ˜¯2022å¹´æå‡ºçš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡expectile regressionå’Œadvantage-weighted behavioral cloningï¼Œåœ¨D4RLåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†SOTAæ€§èƒ½ã€‚ç›¸æ¯”éœ€è¦ensembleçš„EDACï¼ŒIQLå®ç°æ›´ç®€å•ï¼Œè®­ç»ƒæ›´å¿«ã€‚"

**é›†æˆæ–¹æ¡ˆ**ï¼š
> "æˆ‘ä»¬å°†ROERçš„ä¼˜å…ˆçº§æœºåˆ¶é›†æˆåˆ°IQLçš„ä¸‰ä¸ªè®­ç»ƒæ­¥éª¤ä¸­ï¼š(1) Qç½‘ç»œæ›´æ–°ä½¿ç”¨ROERæƒé‡åŠ æƒTD lossï¼›(2) Vç½‘ç»œæ›´æ–°åœ¨expectile lossä¸­å¼•å…¥ROERæƒé‡ï¼›(3) ä½¿ç”¨Vç½‘ç»œçš„TDè¯¯å·®è®¡ç®—ROERä¼˜å…ˆçº§ã€‚è¿™ç§é›†æˆä¿ç•™äº†IQLçš„expectile regressionä¼˜åŠ¿ï¼ŒåŒæ—¶å¼•å…¥äº†ROERçš„æ ·æœ¬é€‰æ‹©æœºåˆ¶ã€‚"

### å®éªŒè®¾è®¡

1. **åŸºç¡€å¯¹æ¯”**
   ```bash
   ./run_iql_comparison.sh HalfCheetah-v2 5
   ./run_iql_comparison.sh Ant-v2 5
   ./run_iql_comparison.sh Hopper-v2 5
   ```

2. **æ¶ˆèå®éªŒ**
   - ä¸åŒexpectileçš„å½±å“
   - ä¸åŒroer_tempçš„å½±å“
   - æœ‰/æ— ROERçš„å¯¹æ¯”

3. **ä¸EDAC+ROERå¯¹æ¯”**
   - IQL+ROER vs EDAC+ROER
   - è®­ç»ƒé€Ÿåº¦å¯¹æ¯”
   - æ€§èƒ½å¯¹æ¯”

## ğŸ“Š ç»“æœå¯è§†åŒ–

ä½¿ç”¨å…±äº«çš„å¯è§†åŒ–å·¥å…·ï¼š

```bash
# ä»edac_roerå¤åˆ¶å¯è§†åŒ–è„šæœ¬
cp ../edac_roer/plot_results.py .

# ç”Ÿæˆå¯¹æ¯”å›¾
python plot_results.py \
    --baseline './results/iql_baseline/*/eval_returns.txt' \
    --roer './results/iql_roer/*/eval_returns.txt' \
    --title 'IQL vs IQL+ROER (HalfCheetah-v2)' \
    --save_dir './plots/'
```

## ğŸ”— å‚è€ƒèµ„æ–™

- [IQLè®ºæ–‡](https://arxiv.org/abs/2110.06169) - Kostrikov et al., 2022
- [ROERè®ºæ–‡](https://arxiv.org/abs/2407.03995) - Li et al., 2024
- [IQLå®˜æ–¹ä»£ç ](https://github.com/ikostrikov/implicit_q_learning)
- [åŸROERä»£ç ](https://github.com/XavierChanglingLi/Regularized-Optimal-Experience-Replay)

## ğŸ‰ æ€»ç»“

**IQL+ROERçš„ä¼˜åŠ¿**ï¼š

âœ… **æ›´ç®€å•** - æ— éœ€ensembleï¼Œä»£ç å°‘
âœ… **æ›´å¿«** - è®­ç»ƒé€Ÿåº¦å¿«
âœ… **æ€§èƒ½æ›´å¥½** - IQLåœ¨D4RLä¸Šè¶…è¶ŠEDAC
âœ… **æ›´ç¨³å®š** - Expectile regressionæ¯”TDæ›´ç¨³å®š
âœ… **åˆ›æ–°æ€§å¼º** - ROER+IQLçš„ç»„åˆå°šæœªè¢«æ¢ç´¢

æ‚¨çš„æ¯•è®¾æœ‰å¾ˆå¥½çš„ç ”ç©¶ä»·å€¼ï¼åŠ æ²¹ï¼ğŸš€

